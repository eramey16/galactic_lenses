{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bcde03b-c644-4878-9642-915e56e68d27",
   "metadata": {},
   "source": [
    "# Notebook 7/29, starting to summarize for thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa771ad5-a693-49a0-9b41-d782e179c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ['SPS_HOME'] = \"/global/homes/e/eramey16/fsps\"\n",
    "from docker import classify\n",
    "from docker import db_util as util\n",
    "\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e78cc8-53b8-4043-8f2f-322d4947855e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classy = classify.Classifier()\n",
    "unlensed_gals = classy.query_galaxy(ra=150, dec=2, radius=5, limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b181372-5dc1-4f4c-93c0-b4c47f377062",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrgs = util.clean_desi(unlensed_gals)\n",
    "g, r, z = lrgs.dered_mag_g, lrgs.dered_mag_r, lrgs.dered_mag_z\n",
    "w1, w2 = lrgs.dered_mag_w1, lrgs.dered_mag_w2\n",
    "cut1 = (z - w1) > (0.8 * (r - z) - 0.6)\n",
    "cut2 = ((g - w1) > 2.9) | ((r - w1) > 1.8)\n",
    "cut3 = (((r-w1) > 1.8*(w1-17.14)) & ((r-w1) > (w1-16.33))) | ((r-w1) > 3.3)\n",
    "print(len(lrgs[cut1 & cut2 & cut3]), \"out of\", len(lrgs)), \"gals\"\n",
    "lrgs = lrgs[cut1 & cut2 & cut3]\n",
    "lrgs['ls_id'] = lrgs['ls_id'].astype(int)\n",
    "# path = os.path.expandvars(\"$SCRATCH/data/monocle/LRGs\")\n",
    "# lrgs[['ls_id']].to_csv(f\"{path}/lensed_LRGs.dat\", index=False)\n",
    "z_unlensed = lrgs['z_phot_median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6283b3-6c31-414b-adf1-862608e10023",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(unlensed_gals['z_phot_median'], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2787b9-ac8e-4404-ab5a-d231367a4ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with classy.engine.connect() as conn:\n",
    "    gal_tbl = sa.Table(\"lrg_train\", classy.meta, autoload_with=classy.engine)\n",
    "    stmt = sa.select(gal_tbl)\n",
    "    lensed_gals = pd.DataFrame(conn.execute(stmt))\n",
    "z_lensed = lensed_gals['z_phot_median']\n",
    "_ = plt.hist(z_lensed, bins=100)\n",
    "len(z_lensed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c75388-06d3-4d4f-9994-ccb4462c098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select galaxies from the same redshift distribution as lensed galaxies (assuming gaussian)\n",
    "# i.e. read lensed LRG table in and plot the redshift distribution\n",
    "def create_matched_unlensed_sample(unlensed_df, lensed_redshifts, n_sample=3000):\n",
    "    # Use more bins for finer matching\n",
    "    bins = np.linspace(lensed_redshifts.min(), lensed_redshifts.max(), 25)\n",
    "    \n",
    "    # Get target distribution\n",
    "    target_hist, _ = np.histogram(lensed_redshifts, bins=bins)\n",
    "    target_proportions = target_hist / target_hist.sum()\n",
    "    \n",
    "    # Sample proportionally from each bin\n",
    "    sampled_indices = []\n",
    "    for i in range(len(bins)-1):\n",
    "        bin_mask = (unlensed_df['z_phot_median'] >= bins[i]) & (unlensed_df['z_phot_median'] < bins[i+1])\n",
    "        bin_candidates = unlensed_df[bin_mask].index\n",
    "        \n",
    "        n_needed = int(target_proportions[i] * n_sample)\n",
    "        if len(bin_candidates) >= n_needed:\n",
    "            sampled_indices.extend(np.random.choice(bin_candidates, n_needed, replace=False))\n",
    "    \n",
    "    return unlensed_df.loc[sampled_indices]\n",
    "\n",
    "def create_2d_matched_sample(unlensed_df, lensed_df, n_sample=3000):\n",
    "    # Create 2D bins for magnitude and redshift\n",
    "    mag_bins = np.linspace(lensed_df['dered_mag_r'].min(), lensed_df['dered_mag_r'].max(), 15)\n",
    "    z_bins = np.linspace(lensed_df['z_phot_median'].min(), lensed_df['z_phot_median'].max(), 15)\n",
    "    \n",
    "    # Get 2D histogram of lensed sample\n",
    "    lensed_hist, _, _ = np.histogram2d(lensed_df['dered_mag_r'], lensed_df['z_phot_median'], \n",
    "                                      bins=[mag_bins, z_bins])\n",
    "    target_proportions = lensed_hist / lensed_hist.sum()\n",
    "    \n",
    "    sampled_indices = []\n",
    "    for i in range(len(mag_bins)-1):\n",
    "        for j in range(len(z_bins)-1):\n",
    "            # Find candidates in this (magnitude, redshift) bin\n",
    "            mag_mask = (unlensed_df['dered_mag_r'] >= mag_bins[i]) & (unlensed_df['dered_mag_r'] < mag_bins[i+1])\n",
    "            z_mask = (unlensed_df['z_phot_median'] >= z_bins[j]) & (unlensed_df['z_phot_median'] < z_bins[j+1])\n",
    "            bin_candidates = unlensed_df[mag_mask & z_mask].index\n",
    "            \n",
    "            n_needed = int(target_proportions[i,j] * n_sample)\n",
    "            if len(bin_candidates) >= n_needed and n_needed > 0:\n",
    "                sampled_indices.extend(np.random.choice(bin_candidates, n_needed, replace=False))\n",
    "    \n",
    "    return unlensed_df.loc[sampled_indices]\n",
    "\n",
    "unlensed_gals = create_2d_matched_sample(lrgs, lensed_gals, n_sample=10*len(z_lensed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca81cef-4461-444f-a36b-37fa847c92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(unlensed_gals['z_phot_median'], bins=1000)\n",
    "_ = plt.hist(lensed_gals['z_phot_median'], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35858c5d-8226-4a8d-95ff-f81bf90d14e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(unlensed_gals['g_r'], unlensed_gals['dered_mag_r'], '.', label='unlensed')\n",
    "plt.plot(lensed_gals['g_r'], lensed_gals['dered_mag_r'], '.', label='lensed')\n",
    "plt.xlabel(\"Color (g-r)\")\n",
    "plt.ylabel(\"Magnitude (R-band)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aa9e4d-0236-4337-9021-c8bd32f8e2a5",
   "metadata": {},
   "source": [
    "# How many galaxies are left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f050e3f-e2c3-4848-8174-e1e1a9811b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ['SPS_HOME'] = \"/global/homes/e/eramey16/fsps\"\n",
    "from docker import classify\n",
    "from docker import db_util as util\n",
    "\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e96b35-4546-4199-91e7-fd327fa8122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg_file = os.path.expandvars(\"$SCRATCH/data/monocle/LRGs/unlensed_h5/unlensed_LRGs.txt\")\n",
    "lrg_file_2 = os.path.expandvars(\"$SCRATCH/data/monocle/LRGs/unlensed_h5/unlensed_LRGs_2.txt\")\n",
    "unlensed_lsids = pd.read_csv(lrg_file, names=['ls_id'])\n",
    "# unlensed_gals['ls_id'].to_csv(lrg_file, header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d96c265-90d4-4369-93e9-d95e26803f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229\n",
      "['10995490503000982', '10995473899849837', '10995493508230774', '10995475401425056', '10995491983595455']\n"
     ]
    }
   ],
   "source": [
    "# lrgs = pd.read_csv(lrg_file)\n",
    "classy = classify.Classifier()\n",
    "unused_lsids = []\n",
    "for ls_id in unlensed_lsids.ls_id:\n",
    "    try:\n",
    "        bkdata, tbldata = classy.get_galaxy(ls_id, tag='unlensed_LRG')\n",
    "        if bkdata.stage[0]!=2: unused_lsids.append(ls_id)\n",
    "    except:\n",
    "        unused_lsids.append(ls_id)\n",
    "print(len(unused_lsids))\n",
    "\n",
    "lrg_commands = [str(ls_id) for ls_id in unused_lsids]\n",
    "# lrg_commands = [stmt + str(ls_id) for ls_id in unused_lsids]\n",
    "# lrg_commands = lrg_commands[100:114]\n",
    "# lrg_commands = stmt + unused_lsids.ls_id.astype(str)\n",
    "# num_files = int(len(lrg_commands)/25)\n",
    "# idxs = np.linspace(0, len(lrg_commands), num_files+1).astype(int)\n",
    "# for i in range(num_files):\n",
    "#     short_commands = lrg_commands.iloc[idxs[i]:idxs[i+1]]\n",
    "    # short_commands.to_csv(command_file+f\"_{i}.sh\", index=False, header=False)\n",
    "# lrg_commands.to_csv(command_file, index=False, header=False)\n",
    "# with open(command_file, 'w') as file:\n",
    "#     # file.write(header+'\\n'.join(lrg_commands))\n",
    "#     file.write('\\n'.join(lrg_commands))\n",
    "with open(lrg_file_2, 'w') as file:\n",
    "    file.write('\\n'.join(lrg_commands))\n",
    "print(lrg_commands[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52957647-191f-43e2-88c0-8b1651dbe7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write an ML training script for these (with RF and XGBoost)\n",
    "# Run and troubleshoot full scene modeling notebook (even without GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4454988-1f38-49f4-ad0d-aa56daa82b98",
   "metadata": {},
   "source": [
    "# Plotting XGBoost Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce5cee07-32fc-4289-b208-ff1b0697d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.pool import NullPool\n",
    "from docker import db_util as util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "159f65b6-1176-47de-a1d3-8ceeb16cff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Colors are already de-reddened\n",
    "# engine = sa.create_engine(util.conn_string, poolclass=NullPool)\n",
    "# with engine.connect() as conn:\n",
    "#     gal_tbl = sa.Table('lrg_train', sa.MetaData(), autoload_with=engine)\n",
    "#     stmt = sa.select(gal_tbl)\n",
    "#     gal_data = pd.DataFrame(conn.execute(stmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1cffd5e-b514-4c48-9c1f-63a1ace8a891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b   c\n",
       "0  1.0  4.0 NaN\n",
       "1  NaN  6.0 NaN"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.DataFrame({'a': [1, np.nan, np.nan], 'b': [4, np.nan, 6], 'c':[np.nan, np.nan, np.nan]})\n",
    "x[x[['a', 'b']].isnull().sum(axis=1)<2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ca8fa50-7758-41b2-95a7-772a7bfc70f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2    False\n",
       "Name: a, dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.a<3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae587c8-cade-4313-92c7-e69f17760c43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyProspector",
   "language": "python",
   "name": "myprospector"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
